---
title: "02 Data acquisition"
author: "Anjali Kabra"
date: "2023-04"
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    collapsed: false
    number_sections: true
    toc_depth: 3
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```

# Data Acquisition

Last compiled: `r Sys.Date()`

I learned how to obtain data via an API or the html/css of a website

# Challange Nr. 1

I enjoy watching twitch at the end of the day, so I decided to make a program that requests the twitch api to give me the currently streaming top 5 streamers. (The request returns the top 20)

## Twitch.tv API

```{r}
library(httr)
library(tidyverse)

client_id = Sys.getenv("client_id")
client_secret = Sys.getenv("client_secret")

url <- "https://id.twitch.tv/oauth2/token"
query <- list(client_id, client_secret, "client_credentials")
names(query) <- c("client_id", "client_secret", "grant_type")


upload <- POST(url,
     query = query) %>% 
  content()


add_headers('Client-ID' = client_id,
            Authorization = paste0("Bearer ", upload$access_token)) %>%
    set_config()

url = 'https://api.twitch.tv/helix/streams'
query <- list(20,      #first
              NULL,    #after
              NULL,    #before
              NULL,    #community_id
              NULL,    #game_id
              NULL,    #language
              NULL,    #type
              NULL,    #user_id
              NULL)    #user_login
names(query) <- c('first',
                  'after',
                  'before',
                  'community_id',
                  'game_id',
                  'language',
                  'type',
                  'user_id',
                  'user_login')

streams <- GET(url,
               query) %>%
  content()
# Streams$Data is list of lists. We want to feed it to as_tibble, for that we need to make a list of
# vectors (when I used list of lists, the output was the type of all values, not the actual values themselves.
#To make vectors, we need lists that have elements of of only the same type. The same-index-elements of the
#inner lists correspond to the same feature (like game_id) so we want to transpose our matrix(list), so that we can
# get values of the same type in each list. Now we can make the lists into vectors
data <- streams$data %>% 
  transpose() %>%         
  simplify_all() %>%
  as_tibble()
data %>%
  head(n=5) 

```
Figure 1: Top 5 streams


# Challange Nr. 2

Scraping rosebike mountainbikes from <https://www.rosebikes.com/bikes/mtb>.

## Rosebike

```{r}
library(tidyverse) # Main Package - Loads dplyr, purrr, etc.
library(rvest)     # HTML Hacking & Web Scraping
library(xopen)     # Quickly opening URLs
library(jsonlite)  # converts JSON files to R objects
library(glue)      # concatenate strings
library(stringi)   # character string/text processing
library(purrr)

extract_price <- function(text) {
  price_str <- str_extract(text, "[0-9]*,*[0-9]*\\.[0-9]*")
  price_str <- gsub(",", "", as.character(price_str))
  return(price_str)
}

make_url <- function(my_string){
  base_url <- "https://www.rosebikes.com"
  glue("{base_url}{my_string}")
}

#all model names have numbers in them
filter_model_names <- function(model_name) {
  condition1 <- str_detect(model_name, "[0-9]")
  condition2 <- str_detect(model_name, "SOUL FIRE")
  if (condition1 | condition2) {
    return(model_name)
  }
  return(NULL)
}

extract_models <- function(model_url) {
  
  css_class_model_name <- ".basic-headline__title"
  # This part extracts the model names
  html_model_names <- read_html(model_url) %>%
    html_nodes(css = css_class_model_name) %>%
    map(html_text) %>%
    map(filter_model_names)
  model_names <- unique(unlist(html_model_names))
  
  
  #This parts extracts the model price
  css_class_model_price = ".catalog-category-model__price-current-value"
  model_prices <- read_html(model_url) %>%
    html_nodes(css = css_class_model_price) %>%
    map(html_text) %>%
    map(extract_price)
  
  #The last prices are the prices of the models
  while (length(model_prices) > length(model_names)) {
    model_prices[1] <- NULL
  }
  model_prices <- model_prices %>%
    unlist() %>%
    as.double()
  
  models_tbl <- tibble(model_names, model_prices)
  
}


extract_models_from_category_list_mtb <- function(bike_url){
  
  bike_price_xml_path = "catalog-category-bikes__price-title"
  category <- str_extract(bike_url, "(?<=/)[a-z]*$")
  css_class <- ".catalog-category-bikes__button"
  
  html_bike <- read_html(bike_url)
  
  html_models_urls <- html_bike %>%
    html_nodes(css = css_class) %>%
    html_attr("href") %>%
    map(make_url)
  
  models_in_category_list <- map(html_models_urls, extract_models)
  models_in_category_list
  models_in_category_tbl <- models_in_category_list[[1]]
  for (i in 2:length(models_in_category_list)) {
    models_in_category_tbl <- add_row(models_in_category_tbl, 
                                      model_names = models_in_category_list[[i]]$model_names,
                                      model_prices = models_in_category_list[[i]]$model_prices)
  }
  
  category = rep(category, times = length(models_in_category_tbl$model_names))
  models_in_category_tbl$category <- category
  return(models_in_category_tbl)
}


home_url <- "https://www.rosebikes.com/bikes"

html_home <- read_html(home_url)
html_categories_urls <- html_home %>%
  html_nodes(css = ".catalog-navigation__link") %>%
  html_attr("href") %>%
  map(make_url)


tbl <- html_categories_urls[[1]] %>%
  extract_models_from_category_list_mtb
tbl 
```
Figure 2: Model names and Model prices (Prices are in Euro)
